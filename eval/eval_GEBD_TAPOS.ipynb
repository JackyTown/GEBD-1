{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of boundaries: 3312\n",
      "total number of frames: 436888\n"
     ]
    }
   ],
   "source": [
    "# load GT\n",
    "with open('../data/export/tapos_annotation_timestamps_myfps.json', 'r') as f:\n",
    "    tapos_dict = json.load(f)\n",
    "    \n",
    "#only need go over action instances that have at least 1 internal boundary    \n",
    "num_bdy_per_action = []\n",
    "num_frames_per_action = []\n",
    "time_duration_per_action = []\n",
    "tapos_dict_val_instance_level_at_least_1_internal_bdy = {}\n",
    "for k in tapos_dict.keys():\n",
    "    for s in tapos_dict[k].keys():\n",
    "        if tapos_dict[k][s]['subset'] == 'val':\n",
    "            if len(tapos_dict[k][s]['substages']) > 2:\n",
    "                num_bdy_per_action.append(len(tapos_dict[k][s]['substages'])-2)\n",
    "                num_frames_per_action.append(tapos_dict[k][s]['substages'][-1]+1-tapos_dict[k][s]['substages'][0])\n",
    "                time_duration_per_action.append(tapos_dict[k][s]['substages_timestamps'][-1]-tapos_dict[k][s]['substages_timestamps'][0])\n",
    "                tapos_dict_val_instance_level_at_least_1_internal_bdy[k+'_'+s] = tapos_dict[k][s]\n",
    "                tapos_dict_val_instance_level_at_least_1_internal_bdy[k+'_'+s]['video_name'] = k\n",
    "                tapos_dict_val_instance_level_at_least_1_internal_bdy[k+'_'+s]['shot_name'] = s\n",
    "\n",
    "print(\"total number of boundaries: \" + str(sum(num_bdy_per_action)))\n",
    "print(\"total number of frames: \" + str(sum(num_frames_per_action)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = 3\n",
    "\n",
    "exp_path = '../data/exp_TAPOS/'\n",
    "output_seg_dir = 'detect_seg'\n",
    "OUTPUT_BDY_PATH = exp_path + output_seg_dir + '/{}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec: 0.4321256038647343\n",
      "prec: 0.7032923832923832\n",
      "F1: 0.535328221432579\n",
      "rec: [0.27747584541062803, 0.3565821256038647, 0.39945652173913043, 0.427536231884058, 0.45018115942028986, 0.4643719806763285, 0.47493961352657005, 0.4830917874396135, 0.4906400966183575, 0.4969806763285024]\n",
      "prec: [0.4515970515970516, 0.5803439803439804, 0.6501228501228501, 0.6958230958230959, 0.7326781326781326, 0.7557739557739558, 0.772972972972973, 0.7862407862407862, 0.7985257985257985, 0.8088452088452088]\n",
      "F1: [0.3437441556012717, 0.4417430334767159, 0.4948569291191322, 0.5296427903497288, 0.5576959042453713, 0.5752758556199739, 0.5883673087712735, 0.5984664297737048, 0.6078174677389191, 0.6156723396296989]\n"
     ]
    }
   ],
   "source": [
    "list_rec = []\n",
    "list_prec = []\n",
    "list_f1 = []\n",
    "\n",
    "for d in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "\n",
    "    tp_all = 0\n",
    "    num_pos_all = 0\n",
    "    num_det_all = 0\n",
    "    \n",
    "    for vid_id in list(tapos_dict_val_instance_level_at_least_1_internal_bdy.keys()):\n",
    "\n",
    "        output_bdy_path = OUTPUT_BDY_PATH.format(vid_id)\n",
    "\n",
    "        if not os.path.exists(output_bdy_path):\n",
    "            num_pos_all += len(tapos_dict_val_instance_level_at_least_1_internal_bdy[vid_id]['substages_myframeidx'])-2\n",
    "            continue\n",
    "        \n",
    "        with open(output_bdy_path, 'rb') as f:\n",
    "            bdy_idx_save = pickle.load(f, encoding='latin1') \n",
    "\n",
    "        bdy_idx_list_smt = np.array(bdy_idx_save['bdy_idx_list_smt'])*downsample # already offset, index starts from 0\n",
    "\n",
    "        v = vid_id[:11]\n",
    "        s = vid_id[12:]\n",
    "        myfps = tapos_dict[v][s]['myfps']\n",
    "        bdy_idx_list_gt = tapos_dict[v][s]['substages_myframeidx'][1:-1]\n",
    "        \n",
    "        ins_start = tapos_dict[v][s]['substages_myframeidx'][0]\n",
    "        ins_end = tapos_dict[v][s]['substages_myframeidx'][-1]\n",
    "        \n",
    "        if bdy_idx_list_gt == []:\n",
    "            continue\n",
    "            \n",
    "        num_pos = len(bdy_idx_list_gt)\n",
    "        num_pos_all += num_pos\n",
    "        \n",
    "        # remove detected boundary outside the action instance\n",
    "        tmp = []\n",
    "        for det in bdy_idx_list_smt:\n",
    "            tmpdet = det + tapos_dict[v][s]['substages_myframeidx'][0]\n",
    "            if tmpdet >= (tapos_dict[v][s]['substages_myframeidx'][0]) and tmpdet <= (tapos_dict[v][s]['substages_myframeidx'][-1]):\n",
    "                tmp.append(tmpdet)\n",
    "        bdy_idx_list_smt = tmp\n",
    "        \n",
    "        if bdy_idx_list_smt == []:\n",
    "            continue\n",
    "            \n",
    "        # compare bdy_idx_list_smt vs. bdy_idx_list_gt\n",
    "        \n",
    "        num_det = len(bdy_idx_list_smt)\n",
    "        num_det_all += num_det\n",
    "        tp = 0\n",
    "        offset_arr = np.zeros((len(bdy_idx_list_gt), len(bdy_idx_list_smt))) \n",
    "        \n",
    "        for ann1_idx in range(len(bdy_idx_list_gt)):\n",
    "            for ann2_idx in range(len(bdy_idx_list_smt)):\n",
    "                offset_arr[ann1_idx, ann2_idx] = abs(bdy_idx_list_gt[ann1_idx]-bdy_idx_list_smt[ann2_idx])\n",
    "        \n",
    "        for ann1_idx in range(len(bdy_idx_list_gt)):\n",
    "            if offset_arr.shape[1] == 0:\n",
    "                break\n",
    "            min_idx = np.argmin(offset_arr[ann1_idx, :])\n",
    "            if offset_arr[ann1_idx, min_idx] <= d*(ins_end-ins_start+1):\n",
    "                tp += 1\n",
    "                offset_arr = np.delete(offset_arr, min_idx, 1)   \n",
    "                \n",
    "        tp_all += tp\n",
    "        \n",
    "    fn_all = num_pos_all - tp_all\n",
    "    fp_all = num_det_all - tp_all\n",
    "    if num_pos_all == 0:\n",
    "        rec = 1\n",
    "    else:\n",
    "        rec = tp_all/(tp_all+fn_all)\n",
    "    if (tp_all+fp_all) == 0:\n",
    "        prec = 0\n",
    "    else:\n",
    "        prec = tp_all/(tp_all+fp_all)\n",
    "    if (rec+prec) == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2*rec*prec/(rec+prec)\n",
    "    list_rec.append(rec); list_prec.append(prec); list_f1.append(f1)\n",
    "\n",
    "print(\"rec: \" + str(np.mean(list_rec))) \n",
    "print(\"prec: \" + str(np.mean(list_prec))) \n",
    "print(\"F1: \" + str(np.mean(list_f1))) \n",
    "\n",
    "print(\"rec: \" + str(list_rec))\n",
    "print(\"prec: \" + str(list_prec))\n",
    "print(\"F1: \" + str(list_f1)) \n",
    "    \n",
    "np.save(exp_path + output_seg_dir + '.eval.rgb.npy', [list_rec, list_prec, list_f1]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### previous code on evaluating PA mistakenly used `bdy_idx_list_smt = bdy_idx_save['bdy_idx_list_smt']*downsample`, where `bdy_idx_save['bdy_idx_list_smt']` is a list in python. This should be corrected to `np.array(bdy_idx_save['bdy_idx_list_smt'])*downsample`.\n",
    "\n",
    "Previous results (note that this is wrong):\n",
    "```python\n",
    "rec: 0.3724033816425121\n",
    "\n",
    "prec: 0.19957928802588995\n",
    "\n",
    "F1: 0.259882005899705\n",
    "\n",
    "rec: [0.1766304347826087, 0.22433574879227053, 0.2660024154589372, 0.3052536231884058, 0.34541062801932365, 0.3888888888888889, 0.43719806763285024, 0.4815821256038647, 0.5256642512077294, 0.5730676328502415]\n",
    "\n",
    "prec: [0.09466019417475728, 0.12022653721682848, 0.14255663430420712, 0.16359223300970874, 0.18511326860841423, 0.20841423948220064, 0.2343042071197411, 0.2580906148867314, 0.28171521035598707, 0.30711974110032364]\n",
    "\n",
    "F1: [0.12326169405815424, 0.15655288664138223, 0.185630004214075, 0.21302149178255372, 0.24104509060261273, 0.2713864306784661, 0.3050990307627475, 0.3360724820901812, 0.3668352296670881, 0.3999157184997893]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
